## ✨ 내용 요약

## Chapter 2. AI 어시스턴트의 작동 원리

### AI 어시스턴트와 프로그래밍 도구

- **주요 도구**: GitHub Copilot, TabNine, Codium AI 등.
- **주요 기능**: 코드 제안, 자동 완성, 테스트 생성, 코드 분석 등.

### 비교: AI 어시스턴트, 지능형 코드 완성, 컴파일러

1. **지능형 코드 완성**: 단순 코드 자동 완성. MS의 IntelliSense가 대표적.
2. **AI 어시스턴트**: LLM 기반으로 사용자 의도와 컨텍스트를 파악해 코드 작성 및 정보 제공.
3. **컴파일러**: 코드 분석 및 최적화 후 실행 가능한 형태로 변환.

### AI 어시스턴트의 발전 단계 _(소스그래프 퀸 슬랙 기준)_

- **Lv. 0**: 미사용
- **Lv. 1**: 코드 완성 (도움 제공)
- **Lv. 2**: 코드 생성 및 수정
- **Lv. 3**: 학습 기반 자동화 (AI 주도)
- **Lv. 4**: 완전 자동화 (복잡한 작업 처리)
- **Lv. 5**: AI가 목표 설정까지 주도

### 트랜스포머와 LLM

- **트랜스포머**:
  - 이전 NLP 모델(RNN)의 한계(기울기 소실/폭주)를 해결.
  - **어텐션 메커니즘**: 단어 간 관계를 이해하고 평가.
    1. **셀프 어텐션**: 긴 텍스트에서도 단어 관계를 정확히 파악.
    2. **멀티 헤드 어텐션**: 다양한 관점에서 단어 간 관계 분석.
- **LLM 활용**: 사전 학습된 모델을 바로 사용하거나 파인 튜닝으로 특정 작업에 최적화 가능.
- **주요 트랜스포머 유형**: GPT(생성형 AI)와 BERT(NLP).

### LLM의 장단점

- **장점**:
  - 방대한 데이터 학습으로 다양한 작업 지원.
  - 오픈소스 LLM으로 사용자 맞춤형 개발 가능.
- **한계**:
  - 매개변수 확장 시 비용과 복잡성 증가.
  - 과적합 위험, 평가의 어려움.
  - 오픈소스 모델은 장기적 유지보수 부족 가능성.

### LLM 성능 평가 지표

- **주요 지표**: BERTScore, BLEU, ROUGE, Perplexity 등.
- **특화 지표**: HumanEval-V는 코드 평가를 위한 특화 지표로 활용 가능.

## 📝 감상 및 리뷰

- 트랜스포머와 어텐션 메커니즘 같은 기술적 개념이 흥미로웠지만, 이를 완전히 이해하기에는 다소 어렵다.

## 🛠️ 실무/프로젝트 적용

- 파인 튜닝을 직접 경험해 보고, 특정 프로젝트나 도메인에 최적화된 모델을 개발하는 데 도전하고 싶다. 이를 통해 AI 어시스턴트의 성능을 더욱 효과적으로 활용할 수 있을 것이다.

## 🔍 추가 자료

- 파인 튜닝의 실무 적용 사례
- 오픈소스 LLM 활용 방법
